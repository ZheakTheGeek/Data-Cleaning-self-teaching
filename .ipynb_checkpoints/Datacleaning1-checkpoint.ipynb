{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lucky-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age         sex          cp      trtbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
      "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
      "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
      "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
      "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
      "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
      "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
      "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
      "\n",
      "            thall      output  \n",
      "count  303.000000  303.000000  \n",
      "mean     2.313531    0.544554  \n",
      "std      0.612277    0.498835  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    1.000000  \n",
      "75%      3.000000    1.000000  \n",
      "max      3.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Data cleaning for Kaggle project 1 - \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart.csv')\n",
    "df2 = pd.read_csv('o2Saturation.csv')\n",
    "\n",
    "#shows us a table of collumns and rows of our data, shows the mean, std, min, max, interquartile range\n",
    "print(df.describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aboriginal-producer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0.0\n",
       "sex         0.0\n",
       "cp          0.0\n",
       "trtbps      0.0\n",
       "chol        0.0\n",
       "fbs         0.0\n",
       "restecg     0.0\n",
       "thalachh    0.0\n",
       "exng        0.0\n",
       "oldpeak     0.0\n",
       "slp         0.0\n",
       "caa         0.0\n",
       "thall       0.0\n",
       "output      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find any null values in our data\n",
    "df.isnull().any()\n",
    "\n",
    "#find the % of null values in our data set (this is more useful in raw data than available data)\n",
    "# currently this line shows that no lines in our data set have null values, and all values are included within this data set\n",
    "df.isnull().sum()/df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-christianity",
   "metadata": {},
   "source": [
    "# Dropping duplicates \n",
    "An important part of Data Sciene and Data cleaning in general is making sure that we don't have excess numbers that skew our results. \n",
    "That being said, it should be obvious why removing duplicate data values is important to getting accurate results.\n",
    "\n",
    "### drop_duplicates(inplace =True)\n",
    "\n",
    "This code causes the data value in the current field to be dropped if it is in fact a duplicate of another value. \n",
    "For those already familiar with python, this is very similar to using array.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-wedding",
   "metadata": {},
   "source": [
    "# Incomplete Data Sets\n",
    "\n",
    "While this has no impact on the data set using in this example, what could we do if our data includes values that are empty (null)?\n",
    "\n",
    "These results might skew our observation or experiment, so it is important to conider these things before we get into working with the data itself.\n",
    "\n",
    "In the below example, we are trying to determine whether or not a certain amount of fields are blank, and if they are, we will remove the collumn from our list of considered items. \n",
    "\n",
    "In the example below, we will use a threshold of 60% by creating a new threshold variable, and applying it to a dropna() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "herbal-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = len(df)*.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-tolerance",
   "metadata": {},
   "source": [
    "# Checking AXIS\n",
    "\n",
    "\n",
    "the axis here refers to whether or not we are dropping collumns or rows, in this case, we will drop collumns with values that are too low\n",
    "### row = 0, collumn = 1\n",
    "if the data has too many null values, it is simply not relevant enough to the study to inclue (it will skew the data disproportionately to reality,\n",
    "or it doesn't corelate at all)\n",
    "\n",
    "additionally, knowing the shape of our data is important \n",
    "first we will check our collumns to see if they meet our threshold cutoff, once we have done that we will work with rows\n",
    "since we have 6 rows in this example project, let's cut out any rows that have 5 or less values\n",
    "again, this is a relatively complete data set, meaning we don't have many null values\n",
    "this type of cleaning becomes EXTREMELY important in larger data sets that are missing relevant information\n",
    "since incomplete results will skew our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "likely-magazine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(thresh=thresh, axis =1).shape\n",
    "df.dropna(thresh=5,axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-disco",
   "metadata": {},
   "source": [
    "# Filling in missing values \n",
    "\n",
    "### Sometimes missing values are useful, but what if we have significant data in our entry, but are missing 1 value?\n",
    "\n",
    "if you were working with machine learning, you could choose to replace missing row values with the mean or median of the group, even IQR\n",
    "this could be useful in instances where, for example, you are conducting a survey, and partiticipants chose not to answer a certain question. \n",
    "that kind of thing COULD be meaningful for very specific types of surveys and help mitigate response bias, or various other factors, depending\n",
    "on the survey method and participants perception of anonymity. This is mostly used for quantitavive values, but with some modifiation could also\n",
    "be used for qualitative ones as well.\n",
    "\n",
    "fill any age field that is missing with the median age of participants \n",
    "this is an example of the numeric data manipulation to \"autofill\" this section for live participants who might be chatting with assistants who\n",
    "they may feel the need to skew the data for (or something, just a rough example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "legal-interview",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.fillna(df.age.median()).isnull().any()\n",
    "# the same could be done for the mean, these are both very common methods for handling missing values, especially with larger sample sizes\n",
    "df.age.fillna(df.age.mean()).isnull().any()\n",
    "\n",
    "# both of these methods will return false, because again, we have no null values, but these would be effective in data sets that are incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-religion",
   "metadata": {},
   "source": [
    "# Text Management\n",
    "next we will talk about text management in theoretical terms. For this example, all of our data is quantitative, but what if for \"sex\" we allowed\n",
    "for nonbinary identifaction (consider the impacts of HRT on heart disease for example, what if we wanted to track data like this?)\n",
    "due to the nature of this particular file, that isn't something we can look at, so let's just consider the possibility and include code to do so.\n",
    "\n",
    "#first we would need to ensure that all of the entered values were all the same case, that way we can more easily work with the data.\n",
    "#henceforth throughout the project, we will refer to this as normalization, not to be confused with vector normalization.\n",
    "\n",
    "First, let's check the first 5 values using the head() method (as a side note, if we wanted to check the end, we could use tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "seven-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-ballot",
   "metadata": {},
   "source": [
    "The collumn on the left is denoting the index at which the value is stored, while the value on the right is telling us what gender the individual is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
